{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenab/Library/r-miniconda-arm64/envs/lineagt-env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import explogreg\n",
    "import torch\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import pyro.optim as optim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "L = 3\n",
    "T = 5 # 6  # Number of time points\n",
    "# x = torch.linspace(0, 10, T).reshape((T,1))  # Time variable\n",
    "x = torch.tensor([0, 56, 84, 112, 168, 280]).unsqueeze(1)  # Time variable\n",
    "\n",
    "# y = torch.tensor([[0, 138, 188, 565, 572, 539], [0, 238, 548, 793, 649, 629], [0, 28, 128, 283, 405, 486]]).T  # Simulated binary outcomes (logistic regression)\n",
    "y = torch.tensor([[0, 3.5, 6, 8, 1, 271], \n",
    "                  [0, 20, 11, 7, 272, 317], \n",
    "                  [0, 2, 2, 5, 2, 245]]).T  # Simulated binary outcomes (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0],\n",
      "        [ 56],\n",
      "        [ 84],\n",
      "        [112],\n",
      "        [168],\n",
      "        [280]])\n",
      "tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  3.5000,  20.0000,   2.0000],\n",
      "        [  6.0000,  11.0000,   2.0000],\n",
      "        [  8.0000,   7.0000,   5.0000],\n",
      "        [  1.0000, 272.0000,   2.0000],\n",
      "        [271.0000, 317.0000, 245.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup [1]:   0%|          | 0/1500 [00:00, ?it/s]\n",
      "\u001b[A\n",
      "Warmup [1]:   0%|          | 1/1500 [00:00,  1.42it/s, step size=1.23e-01, acc. prob=0.667]\n",
      "Warmup [1]:   1%|          | 8/1500 [00:00, 12.92it/s, step size=1.90e-03, acc. prob=0.625]\n",
      "Warmup [1]:   2%|▏         | 34/1500 [00:01, 55.19it/s, step size=1.65e-03, acc. prob=0.749]\n",
      "Warmup [1]:   3%|▎         | 44/1500 [00:01, 64.11it/s, step size=1.70e-03, acc. prob=0.758]\n",
      "Warmup [1]:   4%|▎         | 54/1500 [00:01, 70.78it/s, step size=1.07e-03, acc. prob=0.760]\n",
      "Warmup [1]:   4%|▍         | 64/1500 [00:01, 77.83it/s, step size=9.38e-04, acc. prob=0.763]\n",
      "\u001b[A\n",
      "Warmup [1]:   5%|▍         | 74/1500 [00:01, 51.61it/s, step size=2.64e-03, acc. prob=0.773]\n",
      "Warmup [1]:   5%|▌         | 82/1500 [00:01, 54.63it/s, step size=6.94e-02, acc. prob=0.795]\n",
      "Warmup [1]:   7%|▋         | 110/1500 [00:14,  1.87it/s, step size=1.99e-10, acc. prob=0.718]\n",
      "\u001b[A\n",
      "Warmup [1]:   8%|▊         | 119/1500 [00:27,  1.17s/it, step size=3.20e-10, acc. prob=0.724]\n",
      "Warmup [1]:   8%|▊         | 120/1500 [00:29,  1.22s/it, step size=7.36e-11, acc. prob=0.720]\n",
      "Warmup [1]:   8%|▊         | 124/1500 [00:34,  1.37s/it, step size=1.19e-10, acc. prob=0.723]\n",
      "Warmup [1]:   9%|▊         | 128/1500 [00:40,  1.41s/it, step size=4.30e-10, acc. prob=0.729]\n",
      "Warmup [1]:   9%|▊         | 131/1500 [00:44,  1.41s/it, step size=1.53e-10, acc. prob=0.727]\n",
      "Warmup [1]:   9%|▉         | 133/1500 [00:47,  1.41s/it, step size=8.52e-11, acc. prob=0.726]\n",
      "Warmup [1]:   9%|▉         | 135/1500 [00:50,  1.41s/it, step size=2.79e-10, acc. prob=0.730]\n",
      "Warmup [1]:   9%|▉         | 136/1500 [00:51,  1.41s/it, step size=1.39e-10, acc. prob=0.728]\n",
      "Warmup [1]:   9%|▉         | 137/1500 [00:53,  1.41s/it, step size=2.49e-10, acc. prob=0.730]\n",
      "Warmup [1]:   9%|▉         | 138/1500 [00:54,  1.41s/it, step size=1.87e-10, acc. prob=0.730]\n",
      "Warmup [1]:   9%|▉         | 139/1500 [00:56,  1.41s/it, step size=3.29e-10, acc. prob=0.732]\n",
      "Warmup [1]:   9%|▉         | 140/1500 [00:57,  1.41s/it, step size=1.29e-10, acc. prob=0.729]\n",
      "Warmup [1]:   9%|▉         | 141/1500 [00:58,  1.41s/it, step size=8.91e-11, acc. prob=0.729]\n",
      "Warmup [1]:   9%|▉         | 142/1500 [01:00,  1.42s/it, step size=1.56e-10, acc. prob=0.731]\n",
      "Warmup [1]:  10%|▉         | 143/1500 [01:01,  1.44s/it, step size=2.57e-10, acc. prob=0.732]\n",
      "Warmup [1]:  10%|▉         | 144/1500 [01:03,  1.43s/it, step size=2.40e-10, acc. prob=0.732]\n",
      "Warmup [1]:  10%|▉         | 145/1500 [01:04,  1.42s/it, step size=1.52e-10, acc. prob=0.731]\n",
      "Warmup [1]:  10%|▉         | 146/1500 [01:06,  1.42s/it, step size=2.61e-10, acc. prob=0.733]\n",
      "Warmup [1]:  10%|▉         | 147/1500 [01:07,  1.42s/it, step size=9.71e-11, acc. prob=0.731]\n",
      "Warmup [1]:  10%|▉         | 148/1500 [01:08,  1.42s/it, step size=1.66e-10, acc. prob=0.732]\n",
      "Warmup [1]:  10%|█         | 153/1500 [01:11,  1.50it/s, step size=1.23e-04, acc. prob=0.714]\n",
      "Warmup [1]:  10%|█         | 154/1500 [01:12,  1.18it/s, step size=2.79e-05, acc. prob=0.712]\n",
      "Warmup [1]:  10%|█         | 155/1500 [01:14,  1.04s/it, step size=4.04e-05, acc. prob=0.713]\n",
      "Warmup [1]:  10%|█         | 156/1500 [01:15,  1.20s/it, step size=6.54e-05, acc. prob=0.715]\n",
      "Warmup [1]:  10%|█         | 157/1500 [01:17,  1.26s/it, step size=2.04e-05, acc. prob=0.714]\n",
      "Warmup [1]:  11%|█         | 158/1500 [01:18,  1.30s/it, step size=2.25e-05, acc. prob=0.714]\n",
      "Warmup [1]:  11%|█         | 159/1500 [01:20,  1.33s/it, step size=4.18e-05, acc. prob=0.716]\n",
      "Warmup [1]:  11%|█         | 160/1500 [01:21,  1.36s/it, step size=7.94e-05, acc. prob=0.718]\n",
      "Warmup [1]:  11%|█         | 161/1500 [01:23,  1.37s/it, step size=1.14e-04, acc. prob=0.719]\n",
      "Warmup [1]:  11%|█         | 162/1500 [01:24,  1.38s/it, step size=3.29e-05, acc. prob=0.717]\n",
      "Warmup [1]:  11%|█         | 163/1500 [01:25,  1.39s/it, step size=7.45e-06, acc. prob=0.715]\n",
      "Warmup [1]:  11%|█         | 164/1500 [01:27,  1.45s/it, step size=1.48e-05, acc. prob=0.716]\n",
      "Warmup [1]:  11%|█         | 165/1500 [01:28,  1.44s/it, step size=2.92e-05, acc. prob=0.718]\n",
      "\u001b[A\n",
      "Warmup [1]:  11%|█         | 166/1500 [01:30,  1.44s/it, step size=5.74e-05, acc. prob=0.720]\n",
      "Warmup [1]:  11%|█         | 167/1500 [01:31,  1.44s/it, step size=2.15e-05, acc. prob=0.718]\n",
      "Warmup [1]:  11%|█         | 168/1500 [01:33,  1.45s/it, step size=1.15e-05, acc. prob=0.717]\n",
      "Warmup [1]:  11%|█▏        | 169/1500 [01:34,  1.47s/it, step size=2.26e-05, acc. prob=0.719]\n",
      "Warmup [1]:  11%|█▏        | 170/1500 [01:36,  1.65s/it, step size=1.78e-05, acc. prob=0.719]\n",
      "Warmup [1]:  11%|█▏        | 171/1500 [01:39,  1.82s/it, step size=3.46e-05, acc. prob=0.720]\n",
      "Warmup [1]:  11%|█▏        | 172/1500 [01:40,  1.72s/it, step size=1.31e-05, acc. prob=0.719]\n",
      "Warmup [1]:  12%|█▏        | 173/1500 [01:42,  1.78s/it, step size=2.53e-05, acc. prob=0.720]\n",
      "Warmup [1]:  12%|█▏        | 174/1500 [01:44,  1.78s/it, step size=4.84e-05, acc. prob=0.722]\n",
      "Warmup [1]:  12%|█▏        | 175/1500 [01:46,  1.82s/it, step size=9.16e-05, acc. prob=0.724]\n",
      "Warmup [1]:  12%|█▏        | 176/1500 [01:47,  1.82s/it, step size=1.72e-04, acc. prob=0.725]\n",
      "Warmup [1]:  12%|█▏        | 177/1500 [01:49,  1.86s/it, step size=5.80e-05, acc. prob=0.723]\n",
      "Warmup [1]:  12%|█▏        | 178/1500 [01:51,  1.90s/it, step size=3.83e-05, acc. prob=0.723]\n",
      "Warmup [1]:  12%|█▏        | 179/1500 [01:53,  1.85s/it, step size=7.12e-05, acc. prob=0.724]\n",
      "Warmup [1]:  12%|█▏        | 180/1500 [01:55,  1.75s/it, step size=8.60e-05, acc. prob=0.725]\n",
      "Warmup [1]:  12%|█▏        | 181/1500 [01:56,  1.67s/it, step size=2.17e-05, acc. prob=0.722]\n",
      "Warmup [1]:  12%|█▏        | 182/1500 [01:58,  1.62s/it, step size=3.98e-05, acc. prob=0.724]\n",
      "Warmup [1]:  12%|█▏        | 183/1500 [01:59,  1.65s/it, step size=7.24e-05, acc. prob=0.725]\n",
      "Warmup [1]:  12%|█▏        | 184/1500 [02:01,  1.69s/it, step size=9.57e-05, acc. prob=0.726]"
     ]
    }
   ],
   "source": [
    "obj = explogreg.Regression(x, y)\n",
    "# mcmc_exp = obj.train_mcmc(regr=\"exp\")\n",
    "mcmc_log = obj.train_mcmc(regr=\"log\") #, num_samples=100, warmup_steps=10)\n",
    "\n",
    "# Get posterior samples\n",
    "# posterior_samples_exp = mcmc_exp.get_samples()\n",
    "posterior_samples_log = mcmc_log.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcmc_exp.summary()\n",
    "mcmc_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# for k, v in posterior_samples_exp.items():\n",
    "#     print(k)\n",
    "#     sns.displot(v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate new x values (e.g., test points for prediction)\n",
    "x_test = torch.linspace(0, 10, T)\n",
    "\n",
    "args = posterior_samples_exp[\"fitness\"][:, None] * x_test.unsqueeze(1)\n",
    "y_preds = torch.exp(args)\n",
    "\n",
    "# Compute predictions for each posterior sample\n",
    "y_mean = y_preds.mean(dim=0)  # Mean prediction\n",
    "y_lower = torch.quantile(y_preds, 0.025, dim=0)  # 2.5% quantile (\n",
    "y_upper = torch.quantile(y_preds, 0.975, dim=0)  # 97.5% quantile (upper bound)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x.squeeze(), y[:,0], color=\"black\", label=\"Observed Data\")  # Scatter plot of actual data\n",
    "plt.plot(x_test, y_mean[:,0], label=\"Mean Prediction\", color=\"blue\")\n",
    "plt.fill_between(x_test, y_lower[:,0], y_upper[:,0], color=\"blue\", alpha=0.3, label=\"95% Credible Interval\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.title(\"Bayesian Logistic Regression with 95% Credible Intervals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "for k, v in posterior_samples_log.items():\n",
    "    try:\n",
    "        ax = sns.displot(v.numpy())\n",
    "        ax.set(title=k)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate new x values (e.g., test points for prediction)\n",
    "x_test = torch.linspace(0, 300, 100)\n",
    "\n",
    "args = - posterior_samples_log[\"fitness\"][:, None] * x_test.unsqueeze(1)\n",
    "y_preds = posterior_samples_log[\"carr_capac\"][:, None] / ( 1 + (posterior_samples_log[\"carr_capac\"][:, None] - 1) * torch.exp(args) )\n",
    "\n",
    "# Compute predictions for each posterior sample\n",
    "y_mean = y_preds.mean(dim=0)  # Mean prediction\n",
    "y_lower = torch.quantile(y_preds, 0.05, dim=0)  # 2.5% quantile (\n",
    "y_upper = torch.quantile(y_preds, 0.95, dim=0)  # 97.5% quantile (upper bound)\n",
    "\n",
    "# Plot results\n",
    "\n",
    "for i in range(L):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(x.squeeze(), y[:,i], color=\"black\", label=\"Observed Data\")  # Scatter plot of actual data\n",
    "    plt.plot(x_test, y_mean[:,i], label=\"Mean Prediction\", color=\"blue\")\n",
    "    plt.fill_between(x_test, y_lower[:,i], y_upper[:,i], color=\"blue\", alpha=0.3, label=\"95% Credible Interval\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Bayesian Logistic Regression with 95% Credible Intervals\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lineagt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
